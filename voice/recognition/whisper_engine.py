"""
Optimierte Whisper Speech Recognition Engine f√ºr Kira
"""

import numpy as np
import logging
import time
import whisper
import torch
from dataclasses import dataclass
from typing import Optional, Dict, Any, List
from pathlib import Path
import os

# Logging Setup
logging.basicConfig(level=logging.INFO)
__whisper_engien__ = "voice.recognition.whisper_engine"
logger = logging.getLogger(__whisper_engien__)

def check_mps_compatibility() -> bool:
    """
    Pr√ºft MPS-Kompatibilit√§t f√ºr Whisper
    Retourniert True wenn MPS sicher verwendet werden kann
    """
    if not (hasattr(torch.backends, 'mps') and torch.backends.mps.is_available()):
        return False
    
    try:
        # Teste sparse tensor operations (h√§ufiges Problem mit Whisper auf MPS)
        test_tensor = torch.sparse_coo_tensor(
            indices=torch.zeros(1, 1, dtype=torch.long),
            values=torch.ones(1),
            size=(1,),
            device='mps'
        )
        
        # Teste grundlegende Operationen
        test_dense = torch.randn(10, 10, device='mps')
        _ = test_dense @ test_dense.T
        
        return True
    except Exception as e:
        logger.debug(f"MPS-Kompatibilit√§tstest fehlgeschlagen: {e}")
        return False

from dataclasses import dataclass
from typing import Optional, Dict, Any, List

@dataclass
class WhisperResult:
    """Whisper Ergebnis-Klasse"""
    success: bool
    text: Optional[str] = None
    language: Optional[str] = None
    confidence: float = 0.0
    processing_time: float = 0.0
    error: Optional[str] = None

class WhisperEngine:
    """Optimierte Whisper Speech Recognition Engine"""
    
    def __init__(self, 
                 model_size: str = "base", 
                 language: str = "de",
                 device: str = None,
                 compute_type: str = "float32"):
        
        self.model_size = model_size
        self.language = language
        self.model = None
        self.is_initialized = False
        
        # Optimale Device-Auswahl mit Umgebungsvariablen-Override
        if device:
            self.device = device
        else:
            # Pr√ºfe Umgebungsvariablen f√ºr Device-Override
            env_device = os.getenv('WHISPER_DEVICE', '').lower()
            if env_device in ['cpu', 'cuda', 'mps']:
                self.device = env_device
                logger.info(f"üîß Device per Umgebungsvariable gesetzt: {self.device}")
            else:
                self.device = self._detect_optimal_device()
        
        self.compute_type = compute_type
        
        # Cache Directory
        self.cache_dir = Path(os.getenv('WHISPER_CACHE_DIR', 'voice/models/whisper'))
        self.cache_dir.mkdir(parents=True, exist_ok=True)
        
        # Audio preprocessing statistics
        self.audio_mean = None
        self.audio_std = None
        
        # Performance Tracking
        self.recognition_count = 0
        self.total_recognition_time = 0.0
        self.last_recognition_time = 0.0
        
        logger.info(f"üß† Whisper Engine: {model_size} Model, Sprache: {language}, Device: {self.device}")
    
    def _detect_optimal_device(self) -> str:
        """Erkennt optimales Compute Device mit verbesserter MPS-Kompatibilit√§tspr√ºfung"""
        if torch.cuda.is_available():
            device = "cuda"
            logger.info(f"üéØ CUDA verf√ºgbar: {torch.cuda.get_device_name(0)}")
        elif check_mps_compatibility():
            device = "mps"
            logger.info("üéØ Apple MPS verf√ºgbar und kompatibel")
        else:
            if hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
                logger.warning("‚ö†Ô∏è MPS verf√ºgbar aber nicht kompatibel mit Whisper - verwende CPU")
            device = "cpu"
            logger.info("üéØ Verwende CPU")
        return device

    def initialize(self) -> bool:
        """Initialisiert Whisper Model mit MPS-Kompatibilit√§tspr√ºfungen"""
        try:
            start_time = time.time()
            logger.info(f"üì• Lade Whisper Model '{self.model_size}' auf {self.device}...")
            
            # Lade Model mit optimalen Einstellungen und MPS-Fallback
            try:
                self.model = whisper.load_model(
                    self.model_size,
                    device=self.device,
                    download_root=str(self.cache_dir),
                    in_memory=True
                )
            except Exception as device_error:
                if self.device == "mps":
                    logger.warning(f"‚ö†Ô∏è MPS-Laden fehlgeschlagen: {device_error}")
                    logger.info("üîÑ Versuche Fallback auf CPU...")
                    self.device = "cpu"
                    
                    self.model = whisper.load_model(
                        self.model_size,
                        device=self.device,
                        download_root=str(self.cache_dir),
                        in_memory=True
                    )
                else:
                    raise device_error
            
            # Optimiere Model
            if self.device == "cuda":
                if self.compute_type == "float16":
                    self.model.half()  # Reduziere Pr√§zision f√ºr bessere Performance
            
            load_time = time.time() - start_time
            logger.info(f"‚úÖ Whisper Model geladen auf {self.device} ({load_time:.1f}s)")
            
            # Warm-up mit Test Recognition
            if self._warm_up_model():
                self.is_initialized = True
                return True
            else:
                logger.error("‚ùå Whisper Model Warm-up fehlgeschlagen")
                return False
            
        except Exception as e:
            logger.error(f"‚ùå Whisper Initialisierung fehlgeschlagen: {e}")
            return False
    
    def _warm_up_model(self) -> bool:
        """Warm-up des Models f√ºr bessere erste Performance mit MPS-Fallback"""
        try:
            # Erstelle 2 Sekunden Test-Audio
            dummy_audio = np.zeros(32000, dtype=np.float32)
            
            # Warm-up Recognition mit Fehlerbehandlung
            try:
                with torch.no_grad():
                    _ = self.model.transcribe(
                        dummy_audio,
                        language=self.language,
                        task='transcribe',
                        verbose=False,
                        fp16=False  # Deaktiviere fp16 f√ºr MPS-Kompatibilit√§t
                    )
            except Exception as transcribe_error:
                if self.device == "mps" and "sparse" in str(transcribe_error).lower():
                    logger.warning(f"‚ö†Ô∏è MPS-Transkription fehlgeschlagen: {transcribe_error}")
                    logger.info("üîÑ Fallback auf CPU f√ºr bessere Kompatibilit√§t...")
                    
                    # Lade Model neu auf CPU
                    del self.model
                    self.device = "cpu"
                    
                    self.model = whisper.load_model(
                        self.model_size,
                        device=self.device,
                        download_root=str(self.cache_dir),
                        in_memory=True
                    )
                    
                    # Wiederhole Warm-up auf CPU
                    with torch.no_grad():
                        _ = self.model.transcribe(
                            dummy_audio,
                            language=self.language,
                            task='transcribe',
                            verbose=False
                        )
                else:
                    raise transcribe_error
            
            logger.info(f"‚úÖ Whisper Model Warm-up erfolgreich auf {self.device}")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Whisper Warm-up Fehler: {e}")
            return False
    
    def transcribe(self, audio_data: np.ndarray, sample_rate: int = 16000) -> WhisperResult:
        """Transkribiert Audio zu Text"""
        if not self.is_initialized:
            return WhisperResult(
                success=False,
                error="Whisper nicht initialisiert"
            )
        
        start_time = time.time()
        
        try:
            # Audio Preprocessing
            processed_audio = self._preprocess_audio(audio_data, sample_rate)
            
            # Transkription
            result = self._transcribe_audio(processed_audio)
            
            # Verarbeitung des Ergebnisses
            if result and 'text' in result:
                text = result['text'].strip()
                confidence = result.get('confidence', 0.0)
                detected_language = result.get('language', self.language)
                
                processing_time = time.time() - start_time
                
                # Performance Tracking
                self.recognition_count += 1
                self.total_recognition_time += processing_time
                self.last_recognition_time = processing_time
                
                if text:
                    logger.info(f"‚úÖ Erkannt ({processing_time:.2f}s): '{text}'")
                    return WhisperResult(
                        success=True,
                        text=text,
                        language=detected_language,
                        confidence=confidence,
                        processing_time=processing_time
                    )
                else:
                    logger.warning("‚ö†Ô∏è Keine Sprache erkannt")
                    return WhisperResult(
                        success=False,
                        error="Keine Sprache erkannt",
                        processing_time=processing_time
                    )
            
            return WhisperResult(
                success=False,
                error="Transkription fehlgeschlagen",
                processing_time=time.time() - start_time
            )
            
        except Exception as e:
            logger.error(f"‚ùå Transkription Fehler: {e}")
            return WhisperResult(
                success=False,
                error=str(e),
                processing_time=time.time() - start_time
            )
        
    def _preprocess_audio(self, audio_data: np.ndarray, sample_rate: int) -> np.ndarray:
        """Optimiertes Audio Preprocessing"""
        try:
            # Normalisierung
            if len(audio_data) == 0:
                return np.zeros(16000, dtype=np.float32)
            
            audio_data = audio_data.astype(np.float32)
            
            # Resampling wenn n√∂tig
            if sample_rate != 16000:
                # TODO: Implement resampling
                logger.warning("‚ö†Ô∏è Resampling nicht implementiert")
            
            # Normalisierung
            if np.max(np.abs(audio_data)) > 0:
                audio_data = audio_data / np.max(np.abs(audio_data))
            
            # Statistiken aktualisieren
            if self.audio_mean is None:
                self.audio_mean = np.mean(audio_data)
                self.audio_std = np.std(audio_data)
            else:
                # Exponentielles Moving Average
                alpha = 0.01
                self.audio_mean = (1 - alpha) * self.audio_mean + alpha * np.mean(audio_data)
                self.audio_std = (1 - alpha) * self.audio_std + alpha * np.std(audio_data)
            
            # Standardisierung
            audio_data = (audio_data - self.audio_mean) / (self.audio_std + 1e-10)
            
            return audio_data
            
        except Exception as e:
            logger.error(f"‚ùå Preprocessing Fehler: {e}")
            return audio_data
    
    def _transcribe_audio(self, audio_data: np.ndarray) -> Dict[str, Any]:
        """Interne Transkriptionsmethode mit MPS-Kompatibilit√§t"""
        try:
            with torch.no_grad():
                # Whisper Transkription mit Device-spezifischen Einstellungen
                result = self.model.transcribe(
                    audio_data,
                    language=self.language,
                    task='transcribe',
                    fp16=self.device == 'cuda',  # Nur fp16 f√ºr CUDA, nicht f√ºr MPS
                    verbose=False
                )
                return result
                
        except Exception as e:
            # Bei MPS-Fehlern versuche CPU-Fallback
            if self.device == "mps" and ("sparse" in str(e).lower() or "mps" in str(e).lower()):
                logger.warning(f"‚ö†Ô∏è MPS-Transkription fehlgeschlagen, versuche CPU-Fallback")
                try:
                    # Tempor√§r auf CPU wechseln f√ºr diese Transkription
                    original_device = self.device
                    self.device = "cpu"
                    
                    # Model auf CPU laden falls n√∂tig
                    if str(next(self.model.parameters()).device) != "cpu":
                        self.model = self.model.cpu()
                    
                    with torch.no_grad():
                        result = self.model.transcribe(
                            audio_data,
                            language=self.language,
                            task='transcribe',
                            verbose=False
                        )
                    
                    logger.info("‚úÖ CPU-Fallback erfolgreich")
                    return result
                    
                except Exception as cpu_error:
                    logger.error(f"‚ùå Auch CPU-Fallback fehlgeschlagen: {cpu_error}")
                    return {}
            else:
                logger.error(f"‚ùå Whisper Transkription Fehler: {e}")
                return {}
        
    def get_performance_stats(self) -> Dict[str, Any]:
        """Gibt Performance Statistiken zur√ºck"""
        if self.recognition_count == 0:
            return {
                'average_time': 0,
                'total_time': 0,
                'recognition_count': 0,
                'last_time': 0
            }
            
        return {
            'average_time': self.total_recognition_time / self.recognition_count,
            'total_time': self.total_recognition_time,
            'recognition_count': self.recognition_count,
            'last_time': self.last_recognition_time
        }
    
    def _prepare_audio(self, audio_data: np.ndarray, sample_rate: int) -> Optional[np.ndarray]:
        """Verbesserte Audio-Vorbereitung"""
        try:
            # Konvertierung und Validierung
            audio_data = np.asarray(audio_data, dtype=np.float32)
            
            if len(audio_data) == 0:
                logger.warning("‚ö†Ô∏è Leeres Audio Array")
                return None
            
            # Normalisierung wenn n√∂tig
            max_abs = np.max(np.abs(audio_data))
            if max_abs > 1.0:
                audio_data = audio_data / max_abs
            
            # Resampling wenn n√∂tig
            if sample_rate != 16000:
                try:
                    import librosa
                    audio_data = librosa.resample(
                        audio_data, 
                        orig_sr=sample_rate, 
                        target_sr=16000
                    )
                except ImportError:
                    logger.warning("‚ö†Ô∏è librosa nicht verf√ºgbar - Resampling √ºbersprungen")
            
            # Qualit√§tspr√ºfungen
            duration = len(audio_data) / 16000
            rms = np.sqrt(np.mean(audio_data**2))
            
            if duration < 0.1:
                logger.warning("‚ö†Ô∏è Audio zu kurz (<0.1s)")
                return None
                
            if rms < 0.001:
                logger.warning("‚ö†Ô∏è Audio zu leise")
                return None
            
            return audio_data
            
        except Exception as e:
            logger.error(f"‚ùå Audio Vorbereitung Fehler: {e}")
            return None
    
    def cleanup(self):
        """Verbesserte Cleanup-Routine"""
        try:
            logger.info("üßπ Whisper Engine Cleanup...")
            
            # Performance Report
            if self.recognition_count > 0:
                avg_time = self.total_recognition_time / self.recognition_count
                logger.info(f"üìä Statistik: {self.recognition_count} Erkennungen, "
                          f"‚åÄ {avg_time:.2f}s pro Erkennung")
            
            # Explizites Memory Cleanup
            if self.model is not None:
                del self.model
                if torch.cuda.is_available():
                    torch.cuda.empty_cache()
            
            self.model = None
            self.is_initialized = False
            
            logger.info("‚úÖ Whisper Engine Cleanup abgeschlossen")
            
        except Exception as e:
            logger.error(f"‚ùå Whisper Cleanup Fehler: {e}")

def test_whisper():
    """Test-Funktion"""
    from ..audio.recorder import SimpleAudioRecorder
    
    print("\nüé§ === WHISPER ENGINE TEST ===")
    
    # Engine initialisieren
    engine = WhisperEngine(model_size="base", language="de")
    if not engine.initialize():
        print("‚ùå Whisper Initialisierung fehlgeschlagen")
        return
    
    # Audio aufnehmen
    recorder = SimpleAudioRecorder()
    
    try:
        print("\nSprich einen Satz (3 Sekunden)...")
        for i in range(3, 0, -1):
            print(f"{i}...")
            time.sleep(1)
            
        print("\nüé§ AUFNAHME L√ÑUFT...")
        audio = recorder.record(3.0)
        
        if not audio.success:
            print(f"‚ùå Aufnahme fehlgeschlagen: {audio.error}")
            return
            
        print("‚úÖ Aufnahme erfolgreich")
        
        # Transkription
        print("\nüîç Transkribiere...")
        result = engine.transcribe(audio.data)
        
        # Ergebnisse
        print("\nüìä ERGEBNIS:")
        print(f"Erfolg: {result.success}")
        print(f"Text: {result.text}")
        print(f"Sprache: {result.language}")
        print(f"Confidence: {result.confidence:.2f}")
        print(f"Zeit: {result.processing_time:.2f}s")
        
        if result.error:
            print(f"Fehler: {result.error}")
        
        # Performance Stats
        stats = engine.get_performance_stats()
        print("\n‚ö° PERFORMANCE:")
        print(f"Durchschnittszeit: {stats['average_time']:.2f}s")
        print(f"Erkennungen: {stats['recognition_count']}")
        
        return result.success
        
    except Exception as e:
        print(f"‚ùå Test Fehler: {e}")
        return False
    finally:
        engine.cleanup()

if __name__ == "__main__":
    test_whisper()